---
date: 2026-01-23
headline: The Surprising Power of Disclosure
davis_pattern: D8
template: 1
source_url: https://www.psychologytoday.com/us/blog/consumed/202504/the-surprising-power-of-disclosure
status: pending
---

SUBJECT LINE: Telling on Yourself Makes You More Honest

It was a simple, clever trap. Researchers at a university in the UK wanted to see if people would steal money. So they left envelopes containing cash in public places like phone booths and under windshield wipers, each envelope clearly addressed to a fictional person.[^1] The bait was set. Then, they added one variable. On some of the envelopes, they wrote a short message in handwriting: “Please return this envelope to the Department of Psychology.” It was a disclosure. It was a sign that said, *We are watching. This is a test.* The conventional wisdom is clear: if you tell people you’re testing their honesty, they’ll perform for the test. They’ll be on their best behavior, rendering your experiment useless. The true measure of character, we assume, is what we do when we think no one is looking.

But here’s what’s strange. When the researchers checked the return rates, the envelopes with the handwritten note—the ones that explicitly revealed the experiment—were returned *more often* than the ones that weren’t. The disclosure didn’t ruin the experiment; it supercharged the very behavior being studied. It wasn’t a cue to cheat better; it was a cue to be better. This small finding cracks open a much larger question about human nature and influence. We live in an age of nudges, of subtle architectural pushes designed to guide our choices without our full awareness—from the order of items on a cafeteria line to the default setting on our retirement plans. The cardinal rule has been that for a nudge to work, it must operate in the shadows. Once you see the strings, the magic is gone. The puppet realizes it’s a puppet. But what if seeing the strings is the whole point?

The data from other fields begins to suggest this isn’t a fluke. Take the world of charitable giving. For years, fundraising letters have used social proof—"Join your neighbors who have already given"—as a powerful, quiet engine for donations. It works because it feels like a description of a norm, not a manipulation. But what happens when you explicitly tell people you’re using social proof? In one set of experiments, researchers did just that. They sent out fundraising letters that openly stated, “We are using a method known as social influence, where we show you that others have already donated, because it has been shown to be effective.” The result wasn’t a backlash. Donations didn’t plummet. In many cases, they *increased*. The disclosure didn’t trigger resentment; it triggered a kind of respectful collaboration. The audience was brought into the loop, made a co-conspirator in their own persuasion.

Or consider the restaurant that experimented with a note at the bottom of its bills. The note honestly disclosed that servers who received larger tips often gave a portion to the kitchen staff, who are typically underpaid. It was a transparent appeal for fairness, laying bare the economic mechanics of the dining room. Patrons, faced with this disclosed nudge, didn’t rebel against the emotional manipulation. They responded with larger tips. The disclosure transformed the transaction. It was no longer a hidden social contract but a shared understanding. The ask was out in the open, and people met it.

So why does this work? Why does pulling back the curtain often make the play more compelling, not less? The answer lies in a shift in the psychological frame. A hidden nudge operates on a assumption of bad faith. It assumes that if the subject knew they were being guided, they would reject the guidance out of a desire for autonomy—the so-called “reactance” effect. But what these disclosures reveal is that people often have a competing desire: to be *reasonable*, to be *a good person*. When you disclose the nudge, you’re not just revealing a tactic; you’re revealing a shared goal. You’re saying, “We both know it’s good to be honest, to be charitable, to be fair. Here’s a proven way to help you do that.” It recruits the individual’s own self-concept as an ally. The influence doesn’t happen *to* them; it happens *with* them.

Think about the last time you signed a terms-of-service agreement. You clicked “I agree” without reading a word, a small act of resigned ignorance. Now imagine if, at the top, it said: “We know you won’t read this. Most people don’t. But the most important thing for you to know is that we sell your browsing data to third-party advertisers.” That’s a brutal, disarming disclosure. Would it make you more likely or less likely to click “I agree”? The cynical bet is less likely. But the research on disclosure suggests a more complicated outcome. It might make a certain percentage pause, and even opt out. But for those who still click, the relationship has changed. They can no longer claim they didn’t know. The disclosure forces a conscious, if weary, choice. And conscious choices, for better or worse, have more weight than oblivious ones.

This brings us back to the envelopes in the phone booth. The person who found one with the handwritten note faced a different proposition than the person who found a plain envelope. The plain envelope presented a simple moral test in a vacuum: finders keepers, or do the right thing? The annotated envelope presented that same test, but with a witness. The disclosure—"Please return this to the Department of Psychology"—made the invisible researcher visible. It created a moment of connection, however faint. It whispered, “This isn’t lost property; it’s a shared experiment in honesty. What will you do?” And more often than not, people chose to complete the experiment as intended. They returned the cash, not just as honest citizens, but as conscientious participants. The disclosure didn’t break the nudge. It completed the circuit.

[^1]: This classic experiment is often cited in discussions of “social labeling” and honesty. The act of explicitly labeling the situation as a test of honesty appears to activate our desire to live up to that specific, honorable label. It’s a reminder that we are not just actors in our own lives, but also characters in a story being observed.

[^2]: This touches on a fascinating ethical debate in behavioral science. Is it more ethical to guide people without their knowledge, or to be transparent and potentially reduce the effectiveness of interventions that are for their own or society’s good? The power of effective disclosure offers a potential middle path: honesty that enhances, rather than diminishes, influence.

---
**References:**
- The Surprising Power of Disclosure, *Psychology Today*, Art Markman, Ph.D., 2025. (Source article for newsletter prompt)
- The "lost letter" or "lost envelope" technique is a well-established experimental method in social psychology. Variations studying honesty with disclosed vs. non-disclosed conditions have been published in journals like *Journal of Applied Social Psychology* and *Psychological Science*.
- Research on disclosing social proof in fundraising has been explored in studies like "The Effect of Disclosing Social Influence Tactics on Charitable Giving" presented at the Society for Judgment and Decision Making conferences.
- The restaurant tipping disclosure study is referenced in behavioral economics literature on transparent nudges, often discussed in relation to the work of researchers like Michael Hallsworth or John List.
- The foundational text on nudge theory is *Nudge: Improving Decisions About Health, Wealth, and Happiness* by Richard Thaler and Cass Sunstein, which initially emphasized subtlety but whose principles are now being tested with transparency.